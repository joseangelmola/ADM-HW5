{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Data\n",
    "\n",
    "In this homework, you will work on a dataset that contains information about a group of papers and their citation relationships.\n",
    "\n",
    "Graphs setup\n",
    "Based on the available data, you will create two graphs to model our relationships as follows:\n",
    "\n",
    "Citation graph: This graph should represent the paper's citation relationships. We want this graph to be unweighted and directed. The citation should represent the citation given from one paper to another. For example, if paper A has cited paper B, we should expect an edge from node A to B.\n",
    "\n",
    "Collaboration graph: This graph should represent the collaborations of the paper's authors. This graph should be weighted and undirected. Consider an appropriate weighting scheme for your edges to make your graph weighted.\n",
    "\n",
    "Data pre-processing\n",
    "The dataset is quite large and may not fit in your memory when you try constructing your graph. So, what is the solution? You should focus your investigation on a subgraph. You can work on the most connected component in the graph. However, you must first construct and analyze the connections to identify the connected components.\n",
    "\n",
    "As a result, you will attempt to approximate that most connected component by performing the following steps:\n",
    "\n",
    "Identify the top 10,000 papers with the highest number of citations.\n",
    "\n",
    "Then the nodes of your graphs would be as follows:\n",
    "\n",
    "Citation graph: you can consider each of the papers as your nodes\n",
    "\n",
    "Collaboration graph: the authors of these papers would be your nodes\n",
    "\n",
    "For the edges of the two graphs, you would have the following cases:\n",
    "\n",
    "Citation graph: only consider the citation relationship between these 10,000 papers and ignore the rest.\n",
    "\n",
    "Collaboration graph: only consider the collaborations between the authors of these 10,000 papers and ignore the rest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data we are working with is very large, so we needed to find a way to work with it without loading the entire file into memory at once. We made get_objects function that reads and processes large JSON files incrementally. \n",
    "\n",
    "The other function we worte was the one that takes id of an article as an input and returns its number of citation.\n",
    "\n",
    "Using these two functions, we found 10000 articles with most citations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ijson\n",
    "import heapq\n",
    "\n",
    "def get_objects(filename):\n",
    "    with open(filename, 'r', encoding=\"utf8\") as f:\n",
    "        objects = ijson.items(f, 'item')\n",
    "        for obj in objects:\n",
    "            yield obj\n",
    "\n",
    "#a function that calculates how many citation an input article has\n",
    "def number(id):\n",
    "    num=0\n",
    "    try:\n",
    "        num=len(id['references'])\n",
    "    except:\n",
    "        num=0\n",
    "    return num\n",
    "\n",
    "filename = \"data.json\"\n",
    "objects = get_objects(filename)\n",
    "\n",
    "#top_items is a list of 10000 articles with most citations\n",
    "top_items = heapq.nlargest(10000, objects, key=number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting information relevant for making a graph: first 10000 articles with most citations and their refrences among these 10000 articles\n",
    "\n",
    "Citation graph is a list of dictionaries. Each dictionary has two keys: id and references. Id tells us which article it is and references gives us a list of ids that it cited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "#citation graph\n",
    "rel_art = []\n",
    "#the set of first 10000 articles\n",
    "ids = set(i['id'] for i in top_items)\n",
    "\n",
    "for i in top_items:\n",
    "    obj = {}\n",
    "    obj['id'] = i['id']\n",
    "    #we are not interested if these articles have cited an article that is not in top_articles\n",
    "    obj['references'] = [j for j in i['references'] if j in ids]  \n",
    "    rel_art.append(obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making external .txt file needed for the command line question:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('citation_graph.txt', 'w') as f:\n",
    "    f.write(f'{rel_art}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make a collaboration graph, we had to make one dictionary and a function.\n",
    "\n",
    "Dictionary has author ids as keys and lists of their articles as values.\n",
    "\n",
    "The function uses information from that dictionary to find all the authors who made an article along with an author from the input. It also gives an information about the number of articles that these authors wrote with the one from an input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Creating a dictionary where the keys are author ids and the values are lists of their articles\n",
    "articles_by_author = defaultdict(list)\n",
    "#We iterate over top 10000 articles\n",
    "for item in top_items:\n",
    "    #we iterate over authors of these top articles\n",
    "    for author in item['authors']:\n",
    "        # Using the 'id' component of the author dictionary as the key\n",
    "        author_id = author['id']\n",
    "        articles_by_author[author_id].append(item['id'])\n",
    "\n",
    "# Converting lists of articles to sets so we can find their intersection\n",
    "for author_id in articles_by_author:\n",
    "    articles_by_author[author_id] = set(articles_by_author[author_id])\n",
    "\n",
    "#function that counts how many elements 2 sets have in common\n",
    "def common(set1, set2):\n",
    "    c=list()\n",
    "    c.append(len(set1.intersection(set2)))\n",
    "    c=c+list(set1.intersection(set2))\n",
    "    return c\n",
    "\n",
    "#function that takes an author from an input and returns dictionary with authors as keys and the number of articles they made with the author from an input as values\n",
    "def collaborators(aut): \n",
    "    col = {}\n",
    "    # Use the 'id' component of the input author dictionary as the key\n",
    "    aut_id = aut\n",
    "    for author_id, articles in articles_by_author.items():\n",
    "        c = common(articles, articles_by_author[aut_id])\n",
    "        if (c[0] != 0 and articles!=articles_by_author[aut_id]):\n",
    "            col[author_id] = c\n",
    "    return col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collaboration graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "collaboration_graph=dict()\n",
    "#we iterate over author ids\n",
    "for i in articles_by_author.keys():\n",
    "    #author ids are keys and the output of collaborators function for these ids are values\n",
    "    collaboration_graph[i]=collaborators(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check the accuracy of the graph, we decided to see if its outcome looks as expected and check if the graph is undirected.\n",
    "\n",
    "First, we checked how values of the graph look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 647,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collaboration_graph.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By looking at the output printed, we randomly picked the id that had number 2 as one value and checked what id has these 2 articles in common with it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2096665950: [2, 2811472820, 2973204678]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collaboration_graph[2131767548]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we saw that collaboration_graph[2131767548] gives us information that author with id 2131767548 has two articles with author with an id 2096665950. We wondered if collaboration_graph[2096665950] will provide the same information, aware that if not, our collaboration graph is wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2623494704: [1, 1510836926],\n",
       " 2765995116: [1, 1510836926],\n",
       " 2667035442: [1, 2148956286],\n",
       " 2141747120: [1, 2148956286],\n",
       " 310458393: [1, 2148956286],\n",
       " 2095738856: [1, 2104309040],\n",
       " 2231378115: [2, 2811472820, 2973204678],\n",
       " 2663712704: [2, 2811472820, 2973204678],\n",
       " 2120544271: [2, 2811472820, 2973204678],\n",
       " 2131767548: [2, 2811472820, 2973204678]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collaboration_graph[2096665950]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It provided the same information, which made us confident that accurate information is saved in our collaboration_graph."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 Backend Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "from scipy.stats import scoreatpercentile\n",
    "\n",
    "\"CITATION GRAPH: Unweighted and directed\"\n",
    "\"COLLABORATION GRAPH: Weighted and undirected\"\n",
    "\n",
    "citation_graph_nx = nx.DiGraph()\n",
    "\n",
    "for node in rel_art:\n",
    "    node_id = node[\"id\"]\n",
    "    references = node[\"references\"]\n",
    "    \n",
    "    citation_graph_nx.add_node(node_id)\n",
    "    \n",
    "    for reference in references:\n",
    "        citation_graph_nx.add_edge(node_id, reference)\n",
    "        \n",
    "collaboration_graph_nx = nx.Graph()\n",
    "\n",
    "for node, edges in collaboration_graph.items():\n",
    "    for neighbor, weight in edges.items():\n",
    "        collaboration_graph_nx.add_edge(node, neighbor, weight = weight[0])\n",
    "        collaboration_graph_nx[node][neighbor][\"papers\"] = weight[1:] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functionality 1 - Graph's features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_features(graph, name):\n",
    "    number_nodes = graph.number_of_nodes()\n",
    "    number_edges = graph.number_of_edges()\n",
    "    density = nx.density(graph)\n",
    "    if name == \"Collaboration\":\n",
    "        degree_distribution = nx.degree_histogram(graph)\n",
    "    elif name == \"Citation\":\n",
    "        degree_distribution_citation_in = np.histogram(list(dict(graph.in_degree()).values()))\n",
    "        degree_distribution_citation_out = np.histogram(list(dict(graph.out_degree()).values()))\n",
    "        degree_distribution = [degree_distribution_citation_in, degree_distribution_citation_out]\n",
    "    avg_degree = np.mean(list(dict(graph.degree()).values()))\n",
    "    _95thpercentile = np.percentile(list(dict(graph.degree()).values()), 95)\n",
    "    hubs = [node for node, degree in dict(graph.degree()).items() if degree > _95thpercentile]\n",
    "    is_dense = density >= 0.5\n",
    "    return {\n",
    "        \"Number of nodes\" : number_nodes,\n",
    "        \"Number of edges\" : number_edges,\n",
    "        \"Density\" : density,\n",
    "        \"Degree distribution\" : degree_distribution,\n",
    "        \"Average degree of the graph\" : avg_degree,\n",
    "        \"Graph hubs\" : hubs,\n",
    "        \"Is dense?\" : is_dense        \n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functionality 2 - Nodes' contribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centrality_analysis(graph, node, name):\n",
    "    betweenness_centrality = nx.betweenness_centrality(graph)[node]\n",
    "    pagerank_centrality = nx.pagerank(graph)[node]\n",
    "    closeness_centrality = nx.closeness_centrality(graph)[node]\n",
    "    degree_centrality = nx.degree_centrality(graph)[node]\n",
    "\n",
    "    return {\n",
    "        \"Graph Name\": name,\n",
    "        \"Betweenness Centrality\": betweenness_centrality,\n",
    "        \"PageRank Centrality\": pagerank_centrality,\n",
    "        \"Closeness Centrality\": closeness_centrality,\n",
    "        \"Degree Centrality\": degree_centrality\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functionality 3 - Shortest ordered walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bfs(graph, start_author, end_author):\n",
    "    if start_author not in graph or end_author not in graph:\n",
    "        return \"No path\", 0\n",
    "    elif len(list(graph.neighbors(start_author))) == 0:\n",
    "        return \"No path\", 0\n",
    "    \n",
    "    visited_authors = set()\n",
    "    queue = [(start_author, [], [])]\n",
    "    while queue:\n",
    "        actual_author, path, papers = queue.pop(0)\n",
    "        if actual_author not in visited_authors:\n",
    "            visited_authors.add(actual_author)\n",
    "            if actual_author == end_author:\n",
    "                return path, papers\n",
    "            neighbors = list(graph.neighbors(actual_author))\n",
    "            if len(neighbors) == 0:\n",
    "                return \"No path\", 0\n",
    "            for neigh in neighbors:\n",
    "                if neigh not in visited_authors:\n",
    "                    queue.append((neigh, path + [(actual_author, neigh)], papers + [graph[actual_author][neigh][\"papers\"][0]]))\n",
    "    return \"No path\", 0   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shortest_path_order(graph, start_author, end_author, authors, N):\n",
    "    graph_degrees = dict(graph.degree())\n",
    "    sorted_degrees = sorted(graph_degrees, key = graph_degrees.get, reverse = True)[:N]\n",
    "    top_authors = [author for author in sorted_degrees]\n",
    "    graph = graph.subgraph(top_authors)\n",
    "    authors_list = authors.copy()\n",
    "    n = len(authors)\n",
    "    general_path = []\n",
    "    papers_visited = []\n",
    "    authors = set(authors)\n",
    "    path, papers = bfs(graph, start_author, authors_list[0])\n",
    "    papers_visited.append(papers)\n",
    "    if path == \"No path\":\n",
    "        return path, 0\n",
    "    else:\n",
    "        authors_path = set([item for tup in path[1 : len(path) - 1] for item in tup])\n",
    "        if len(authors_path.intersection(authors)) != 0:\n",
    "            return \"Order has not been respected\", 0\n",
    "        else:\n",
    "            general_path = general_path + path\n",
    "            authors.discard(authors_list[0])\n",
    "    for i in range(1, n - 1):\n",
    "        path, papers = bfs(graph, authors_list[i], authors_list[i + 1])\n",
    "        papers_visited.append(papers)\n",
    "        if path == \"No path\":\n",
    "            return path, 0\n",
    "        else:\n",
    "            authors_path = set([item for tup in path[1 : len(path) - 1] for item in tup])\n",
    "        if len(authors_path.intersection(authors)) != 0:\n",
    "            return \"Order has not been respected\", 0\n",
    "        else:\n",
    "            general_path = general_path + path\n",
    "            authors.discard(authors_list[i])\n",
    "            authors.discard(authors_list[i + 1])\n",
    "    path, papers=bfs(graph, authors_list[n - 1], end_author)\n",
    "    papers_visited.append(papers)\n",
    "    if path == \"No path\":\n",
    "        return path, 0\n",
    "    else:\n",
    "        authors_path = set([item for tup in path[1 : len(path) - 1] for item in tup])\n",
    "        if len(authors_path.intersection(authors)) != 0:\n",
    "            return \"Order has not been respected\", 0\n",
    "        else:\n",
    "            general_path = general_path + path\n",
    "            papers_visited.append(papers)\n",
    "            authors.discard(authors_list[n - 1])\n",
    "    return general_path, papers_visited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(26483632, 226801178),\n",
       "  (2913115457, 2103279906),\n",
       "  (2103279906, 2097487609),\n",
       "  (2097487609, 2327703972),\n",
       "  (2327703972, 2156575750),\n",
       "  (2156575750, 2161461259),\n",
       "  (2161461259, 2567820109),\n",
       "  (2567820109, 2309817396),\n",
       "  (2309817396, 2149056991),\n",
       "  (2149056991, 1941780408),\n",
       "  (1941780408, 2149056991),\n",
       "  (2149056991, 2309817396),\n",
       "  (2309817396, 2567820109),\n",
       "  (2567820109, 1965944055),\n",
       "  (1965944055, 2107148058),\n",
       "  (2107148058, 2125050856),\n",
       "  (2125050856, 2153840244),\n",
       "  (2153840244, 2135838853),\n",
       "  (2135838853, 323870348),\n",
       "  (323870348, 60615692),\n",
       "  (60615692, 323870348),\n",
       "  (323870348, 2135838853),\n",
       "  (2135838853, 2153840244),\n",
       "  (2153840244, 2125050856),\n",
       "  (2125050856, 2131748517),\n",
       "  (2131748517, 2065247233),\n",
       "  (2065247233, 1964468254),\n",
       "  (1964468254, 316764885),\n",
       "  (316764885, 29319384),\n",
       "  (29319384, 310458393),\n",
       "  (310458393, 2096665950),\n",
       "  (2096665950, 2623494704),\n",
       "  (2623494704, 2096665950),\n",
       "  (2096665950, 310458393),\n",
       "  (310458393, 29319384),\n",
       "  (29319384, 316764885),\n",
       "  (316764885, 2184897463),\n",
       "  (2184897463, 2152717402),\n",
       "  (2152717402, 2567820109),\n",
       "  (2567820109, 2309817396),\n",
       "  (2309817396, 2149056991),\n",
       "  (2149056991, 355346436)],\n",
       " [[2753412869],\n",
       "  [2803856670],\n",
       "  [2029350555,\n",
       "   2604813584,\n",
       "   2890707978,\n",
       "   2995871203,\n",
       "   2973353912,\n",
       "   1562757257,\n",
       "   2787567451,\n",
       "   2910880405],\n",
       "  [2910880405,\n",
       "   2787567451,\n",
       "   1562757257,\n",
       "   2074709832,\n",
       "   2606297994,\n",
       "   1980035202,\n",
       "   2778363563,\n",
       "   2340600537,\n",
       "   2014084212,\n",
       "   2104176208],\n",
       "  [2104176208,\n",
       "   2014084212,\n",
       "   2340600537,\n",
       "   2778363563,\n",
       "   2964048168,\n",
       "   2107561590,\n",
       "   2128508520,\n",
       "   2148628210,\n",
       "   1965895579,\n",
       "   1502503438,\n",
       "   2148956286,\n",
       "   1510836926],\n",
       "  [1510836926,\n",
       "   2148956286,\n",
       "   1502503438,\n",
       "   1965895579,\n",
       "   2148628210,\n",
       "   2164850771,\n",
       "   1810406100,\n",
       "   1562757257,\n",
       "   2787567451,\n",
       "   2910880405],\n",
       "  [1510836926,\n",
       "   2148956286,\n",
       "   1502503438,\n",
       "   1965895579,\n",
       "   2148628210,\n",
       "   2164850771,\n",
       "   1810406100,\n",
       "   1562757257,\n",
       "   2787567451,\n",
       "   2910880405]])"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_author = 26483632\n",
    "authors_list = [226801178, 2913115457, 2103279906, 1941780408, 60615692, 2623494704]\n",
    "final_autor = 355346436\n",
    "shortest_path_order(collaboration_graph_nx, start_author, final_autor, authors_list, 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functionality 4 - Disconnecting Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disconnegting_graphs(graph, authorA, authorB, N):\n",
    "    graph_degrees = dict(graph.degree())\n",
    "    sorted_degrees = sorted(graph_degrees, key = graph_degrees.get, reverse = True)[:N]\n",
    "    top_authors = [author for author in sorted_degrees]\n",
    "    graph = graph.subgraph(top_authors)    \n",
    "    modified_graph = graph.copy()\n",
    "    authorA_nodes_deleted = []\n",
    "    authorB_nodes_deleted = []\n",
    "    remEdges = 0\n",
    "    while len(modified_graph) != 2:\n",
    "        if remEdges % 2 == 0 and len(list(modified_graph.neighbors(authorA))) > 0:\n",
    "            node1 = authorA\n",
    "            neighs_node = modified_graph[node1]\n",
    "            neighs = sorted(neighs_node, key=lambda x: neighs_node[x]['weight'], reverse=True)\n",
    "            if authorA in neighs:\n",
    "                neighs.remove(authorA)\n",
    "            if authorB in neighs:\n",
    "                neighs.remove(authorB)\n",
    "            if len(neighs) == 0:\n",
    "                remEgdes += 1\n",
    "                continue\n",
    "            node2 = neighs[-1]\n",
    "            modified_graph = nx.contracted_edge(modified_graph, (node1, node2))\n",
    "            authorA_nodes_deleted.append(node2)\n",
    "            remEdges += 1\n",
    "        elif remEdges % 2 == 1 and len(list(modified_graph.neighbors(authorB))) > 0:\n",
    "            node1 = authorB\n",
    "            neighs_node = modified_graph[node1]\n",
    "            neighs = sorted(neighs_node, key=lambda x: neighs_node[x]['weight'], reverse=True)\n",
    "            if authorA in neighs:\n",
    "                neighs.remove(authorA)\n",
    "            if authorB in neighs:\n",
    "                neighs.remove(authorB)\n",
    "            if len(neighs) == 0:\n",
    "                remEdges += 1\n",
    "                continue\n",
    "            node2 = neighs[-1]\n",
    "            modified_graph = nx.contracted_edge(modified_graph, (node1, node2))\n",
    "            authorB_nodes_deleted.append(node2)\n",
    "            remEdges += 1\n",
    "        \n",
    "    authorA_nodes_deleted.append(authorA)\n",
    "    authorB_nodes_deleted.append(authorB)\n",
    "\n",
    "    subgraph_authorA = nx.subgraph(graph,authorA_nodes_deleted)\n",
    "    subgraph_authorB = nx.subgraph(graph,authorB_nodes_deleted)\n",
    "    return len(graph.edges) - len(subgraph_authorA) - len(subgraph_authorB), subgraph_authorA, subgraph_authorB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(313,\n",
       " <networkx.classes.graph.Graph at 0x18a14c52530>,\n",
       " <networkx.classes.graph.Graph at 0x18a14c51e40>)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authorA = 2110139497\n",
    "authorB= 2295564484\n",
    "disconnegting_graphs(collaboration_graph_nx, authorA, authorB, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functionality 5 - Extracting Communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_to_remove(graph):\n",
    "    G_dict = nx.edge_betweenness_centrality(graph)\n",
    "    edge = ()\n",
    "\n",
    "  # extract the edge with highest edge betweenness centrality score\n",
    "    for key, value in sorted(G_dict.items(), key=lambda item: item[1], reverse = True):\n",
    "        edge = key\n",
    "        break\n",
    "\n",
    "    return edge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "def girvan_newman(graph, N, paper_1, paper_2):\n",
    "    graph_degrees = dict(graph.degree())\n",
    "    sorted_degrees = sorted(graph_degrees, key = graph_degrees.get, reverse = True)[:N]\n",
    "    top_authors = [author for author in sorted_degrees]\n",
    "    graph = graph.subgraph(top_authors).to_undirected()\n",
    "    sg = nx.connected_components(graph)\n",
    "    sg_count = nx.number_connected_components(graph)\n",
    "    edges_removed = 0\n",
    "    while sg_count == 1:\n",
    "        graph.remove_edge(edge_to_remove(graph)[0], edge_to_remove(graph)[1])\n",
    "        edges_removed += 1\n",
    "        sg = list(nx.connected_components(graph))\n",
    "        sg_count = nx.number_connected_components(graph)\n",
    "    sameCommunity = False\n",
    "    for community in sg:\n",
    "        if paper_1 in community and paper_2 in community:\n",
    "            sameCommunity = True\n",
    "            break\n",
    "    return sg, edges_removed, sameCommunity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([{1511198016, 1538284222, 1553243659, 2107460837, 2149202473}, {1642285091}],\n",
       " 2,\n",
       " True)"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strongly_connected_components = nx.strongly_connected_components(citation_graph_nx)\n",
    "largest_component = max(strongly_connected_components, key=len)\n",
    "citation_subgraph = citation_graph_nx.subgraph(largest_component)\n",
    "\n",
    "girvan_newman(citation_subgraph, 1000, 1511198016, 2149202473)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
